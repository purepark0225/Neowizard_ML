{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "508825c7",
   "metadata": {},
   "source": [
    "### 신경망(Neural network) - concept(I)\n",
    "- 신경 세포 뉴련(neuron)은 이전 뉴런으로부터 입력신호를 받아 또 다른 신호를 발생시킴\n",
    "\n",
    "- 그러나 입력에 비례해서 출력을 내는 형태 (y=WX) 가 아니라, 입력값들의 모든 합이 어느 임계점(threshold)에 도달해야만 출력 신호를 발생시킴.\n",
    "\n",
    "- 이처럼 입력신호를 받아 특정값의 임꼐점을 넘어서는 경우에, 출력을 생성해주는 함수를 활성화 함수(activation function)라고 하는데, 지금까지 사용해왔던 Logistic Regression 시스템의 sigmoid 함수가 대표적인 활성화함수이다. 즉, sigmoid에서의 임계점은 0.5로서, 입력값 합이 0.5보다 크다면 1을 출력으로 내보내고, 0.5보다 값이 작으면 출력으로 내보내고, 0.5 보다 값이 작으면 출력을 내보내지 않는다고 볼 수 있다.(0은 출력이 없는 상태)\n",
    "\n",
    " - 활성화함수 : sigmoid, ReLU, Leaky ReLU, hyperbolic tangent(tanh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc5b7ca",
   "metadata": {},
   "source": [
    "### 신경망(Neural network) - concept(II)\n",
    "- 신경 세포인 뉴런 동작 원리를 머신러닝에 적용하기 위해서는, \n",
    "\n",
    "1) 입력 신호와 가중치를 곱하고 적당한 바이어스를 더한 후(Linear Regression)\n",
    "\n",
    "2) 그 값을 활성화 함수(sigmoid) 입력으로 전달(Classification)해서 sigmoid 함수 임계점 0.5를 넘으면 1을, 그렇지 않으면 0을 다음의 뉴런으로 전달해주는\n",
    "\n",
    "=> multi-variable Logistic Regression 시스템 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1690a48",
   "metadata": {},
   "source": [
    "### 딥러닝(Deep Learning) - concept(I)\n",
    "- 노드(node): 1개의 logistic regression을 나타냄\n",
    "- 노드가 서로 연결되어 있는 신경망 구조를 바탕으로 입력층(Input Layer), 1개 이상의 은닉층(Hidden Layer), 출력층(Output Layer)을 구축하고, 출력층(Output Layer)에서의 오차를 기반으로 각 노드(뉴런)의 가중치(Weight)를 학습하는 머신러닝 한 분야\n",
    "- [참고] 딥러닝 구조에서 1개 이상의 은닉층(hidden layer)을 이용하여 학습시키면 정확도가 높은 결과를 얻을 수 있다고 알려져 있음. 즉 은닉층을 깊게(Deep)할수록 정확도가 높아진다고 해서 딥(Deep)러닝이라는 용어가 사용되고 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72b71eb",
   "metadata": {},
   "source": [
    "### 딥러닝(Deep Learning) - concept(II)\n",
    "- (딥러닝 propagation 이미지 첨부)\n",
    "- 가중치 w21: 특정 계층의 노드 1에서 다음 계층의 노드 2로 전달되는 신호를 강화 또는 약화시키는 가중치(즉, 다음 계층의 노드 번호가 먼저 나옴)\n",
    "- 가중치 w2N: 특정 계층의 노드 N에서 다음 계층의 노드 2로 전달되는 신호를 강화 또는 약화시키는 가중치(즉, 다음 계층의 노드 번호가 먼저 나옴)\n",
    "\n",
    "=> 이러한 가중치 값들은, 층과 층 사이의 모든 노드에 초기화되어 있으며, 데이터가 입력층에서 출력층으로 전파(propagation)될 때, 각 층에 있는 노드의 모든 가중치(w11, w12,...,wMK,  wLK등 )는 신호를 약화시키거나(낮은 가중치) 또는 신호를 강화(높은 가중치) 시키며, 최종적으로는 오차가 최소값이 될 때 최적의 값을 가지게 됨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
