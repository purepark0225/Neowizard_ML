{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87e24319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W =  [[0.5044036]] , W.shape =  (1, 1) , b =  [0.19215832] , b.shape =  (1,)\n",
      "initial error value =  22.767046168345768 initial W =  [[0.5044036]] \n",
      " , b =  [0.19215832]\n",
      "step =  0 error value =  7.868623214426062 W =  [[0.09737796]] b =  [0.15563017]\n",
      "step =  400 error value =  2.9187188130572124 W =  [[0.43231746]] b =  [-4.24988129]\n",
      "step =  800 error value =  1.7620961761434477 W =  [[0.45888986]] b =  [-5.71476244]\n",
      "step =  1200 error value =  1.505424175370773 W =  [[0.53491682]] b =  [-6.72691807]\n",
      "step =  1600 error value =  1.3439924700917047 W =  [[0.59543001]] b =  [-7.53036559]\n",
      "step =  2000 error value =  1.22974268862108 W =  [[0.64646092]] b =  [-8.20645335]\n",
      "step =  2400 error value =  1.1429531209331045 W =  [[0.69101859]] b =  [-8.79574443]\n",
      "step =  2800 error value =  1.073840246564541 W =  [[0.73083722]] b =  [-9.32159572]\n",
      "step =  3200 error value =  1.0169216151138765 W =  [[0.7670148]] b =  [-9.79877915]\n",
      "step =  3600 error value =  0.9688511316323558 W =  [[0.80029411]] b =  [-10.23727711]\n",
      "step =  4000 error value =  0.9274530845218586 W =  [[0.83120315]] b =  [-10.64417697]\n",
      "step =  4400 error value =  0.8912418843208652 W =  [[0.86013181]] b =  [-11.02470705]\n",
      "step =  4800 error value =  0.859162899728157 W =  [[0.88737697]] b =  [-11.38284394]\n",
      "step =  5200 error value =  0.8304432987763015 W =  [[0.91317034]] b =  [-11.72168866]\n",
      "step =  5600 error value =  0.8045016141595663 W =  [[0.93769662]] b =  [-12.04371024]\n",
      "step =  6000 error value =  0.7808905037669763 W =  [[0.96110557]] b =  [-12.3509094]\n",
      "step =  6400 error value =  0.759259188497694 W =  [[0.98352051]] b =  [-12.64493195]\n",
      "step =  6800 error value =  0.7393280315337715 W =  [[1.00504428]] b =  [-12.92714958]\n",
      "step =  7200 error value =  0.7208708708705012 W =  [[1.02576367]] b =  [-13.19871866]\n",
      "step =  7600 error value =  0.7037024522973936 W =  [[1.04575259]] b =  [-13.46062385]\n",
      "step =  8000 error value =  0.6876693060917585 W =  [[1.06507464]] b =  [-13.71371121]\n",
      "step =  8400 error value =  0.6726430028030789 W =  [[1.0837849]] b =  [-13.95871357]\n",
      "step =  8800 error value =  0.6585150865096985 W =  [[1.10193146]] b =  [-14.19627021]\n",
      "step =  9200 error value =  0.6451932126402566 W =  [[1.11955658]] b =  [-14.42694256]\n",
      "step =  9600 error value =  0.6325981651122581 W =  [[1.13669761]] b =  [-14.65122654]\n",
      "step =  10000 error value =  0.6206615249861753 W =  [[1.15338774]] b =  [-14.86956264]\n"
     ]
    }
   ],
   "source": [
    "# 1) 학습데이터(Training data) 준비\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([2, 4, 6, 8, 10, 12, 14, 16, 18, 20]).reshape(10,1)\n",
    "t_data = np.array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1]).reshape(10,1)\n",
    "\n",
    "# 2) 임의의 직선 z = Wx + b 정의(임의의 값으로 가중치 W, 바이어스 b 초기화)\n",
    "W = np.random.rand(1,1)\n",
    "b = np.random.rand(1)\n",
    "print(\"W = \", W, \", W.shape = \", W.shape, \", b = \", b, \", b.shape = \", b.shape)\n",
    "\n",
    "# 3) 손실함수 E(W, b) 정의\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))\n",
    "\n",
    "def loss_func(x, t):\n",
    "    delta = 1e-7 # log 무한대 발산 방지\n",
    "    \n",
    "    z = np.dot(x, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    # cross-entropy\n",
    "    return -np.sum(t * np.log(y + delta) + (1-t) * np.log((1-y)+delta))\n",
    "\n",
    "\n",
    "# 4) 수치미분 numerical_derivative 및 utility 함수 정의\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags = ['multi_index'], op_flags = ['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x\n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad\n",
    "\n",
    "def error_val(x, t):\n",
    "    delta = 1e-07 # log 무한대 발산 방지\n",
    "    \n",
    "    z = np.dot(x, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    # cross-entropy\n",
    "    return -np.sum( t*np.log(y + delta) + (1-t)*np.log((1-y) + delta))\n",
    "\n",
    "def predict(x):\n",
    "    z =  np.dot(x ,W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    if y > 0.5:\n",
    "        result = 1 # True\n",
    "    else:\n",
    "        result = 0 # False\n",
    "        \n",
    "    return y, result\n",
    "\n",
    "# 5) 학습율 초기화 및 손실함수가 최소가 될 때까지 W, b 업데이트\n",
    "\n",
    "learning_rate = 1e-2 # 발산하는 경우, 1e-3 ~ 1e-6 등으로 바꾸어서 실행\n",
    "\n",
    "f = lambda x : loss_func(x_data, t_data) # f(x) = loss_func(x_data, t_data)\n",
    "print(\"initial error value = \", error_val(x_data, t_data), \"initial W = \", W, \"\\n\", \", b = \", b)\n",
    "\n",
    "for step in range(10001):\n",
    "    W -= learning_rate * numerical_derivative(f, W)\n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "    \n",
    "    if (step % 400 == 0):\n",
    "        print(\"step = \", step, \"error value = \", error_val(x_data, t_data), \"W = \", W, \"b = \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71331bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.10906237e-05]] 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1.10906237e-05]]), 0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(real_val, logical_val) = predict(3) # 공부시간 3시간 미래값 예측\n",
    "\n",
    "print(real_val, logical_val) # 0.1 보다 작은 real값\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cba10018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99132011]] 1\n"
     ]
    }
   ],
   "source": [
    "(real_val, logical_val) = predict(17) # 공부시간 17시간 미래값 예측\n",
    "\n",
    "print(real_val, logical_val) # real_val = 공부시간 17시간이면 99.1% 확률로 합격할 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f4d0413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W =  [[0.36151567]\n",
      " [0.62842551]] , W.shape =  (2, 1) , b =  [0.8247337] , b.shape =  (1,)\n",
      "initial error value =  26.886908645055026 initial W =  [[0.36151567]\n",
      " [0.62842551]] \n",
      " , b =  [0.8247337]\n",
      "step =  0 error value =  16.127083117334063 W =  [[0.1621146 ]\n",
      " [0.36937122]] , b =  [0.7860258]\n",
      "step =  400 error value =  2.3338595225925953 W =  [[ 0.41286012]\n",
      " [-0.09160248]] , b =  [-2.50859233]\n",
      "step =  800 error value =  1.6145077332145628 W =  [[ 0.53091894]\n",
      " [-0.02878952]] , b =  [-4.19145555]\n",
      "step =  1200 error value =  1.2923648247837485 W =  [[0.61920434]\n",
      " [0.00742894]] , b =  [-5.32250539]\n",
      "step =  1600 error value =  1.1060128351971474 W =  [[0.69025659]\n",
      " [0.03302471]] , b =  [-6.18374284]\n",
      "step =  2000 error value =  0.9821541537732866 W =  [[0.75003137]\n",
      " [0.05330718]] , b =  [-6.88610878]\n",
      "step =  2400 error value =  0.8923723675983923 W =  [[0.80179233]\n",
      " [0.07060595]] , b =  [-7.48414523]\n",
      "step =  2800 error value =  0.8233440191039261 W =  [[0.8475234 ]\n",
      " [0.08611751]] , b =  [-8.00852218]\n",
      "step =  3200 error value =  0.7679803488842356 W =  [[0.88852482]\n",
      " [0.10052027]] , b =  [-8.47812124]\n",
      "step =  3600 error value =  0.7221513726797787 W =  [[0.92569878]\n",
      " [0.11422442]] , b =  [-8.90535696]\n",
      "step =  4000 error value =  0.683280240680931 W =  [[0.9597003 ]\n",
      " [0.12748794]] , b =  [-9.29881142]\n",
      "step =  4400 error value =  0.6496706613344873 W =  [[0.99102314]\n",
      " [0.14047586]] , b =  [-9.66465638]\n",
      "step =  4800 error value =  0.6201569343767447 W =  [[1.0200515 ]\n",
      " [0.15329308]] , b =  [-10.00747402]\n",
      "step =  5200 error value =  0.5939092700392302 W =  [[1.04709264]\n",
      " [0.1660038 ]] , b =  [-10.33075668]\n",
      "step =  5600 error value =  0.5703194115080252 W =  [[1.07239803]\n",
      " [0.17864384]] , b =  [-10.63722498]\n",
      "step =  6000 error value =  0.5489303020134574 W =  [[1.09617754]\n",
      " [0.19122895]] , b =  [-10.92903791]\n",
      "step =  6400 error value =  0.5293911300027909 W =  [[1.118609  ]\n",
      " [0.20376088]] , b =  [-11.20793622]\n",
      "step =  6800 error value =  0.511427624157912 W =  [[1.1398449]\n",
      " [0.2162318]] , b =  [-11.4753429]\n",
      "step =  7200 error value =  0.4948218513097506 W =  [[1.16001707]\n",
      " [0.22862785]] , b =  [-11.73243549]\n",
      "step =  7600 error value =  0.4793981278072681 W =  [[1.17924004]\n",
      " [0.24093181]] , b =  [-11.98019913]\n",
      "step =  8000 error value =  0.4650129764254858 W =  [[1.19761366]\n",
      " [0.25312518]] , b =  [-12.21946618]\n",
      "step =  8400 error value =  0.45154782855208125 W =  [[1.21522504]\n",
      " [0.26518971]] , b =  [-12.45094648]\n",
      "step =  8800 error value =  0.4389036315321495 W =  [[1.23215019]\n",
      " [0.27710843]] , b =  [-12.67525054]\n",
      "step =  9200 error value =  0.42699680472916585 W =  [[1.24845543]\n",
      " [0.28886637]] , b =  [-12.8929077]\n",
      "step =  9600 error value =  0.4157561673080568 W =  [[1.26419856]\n",
      " [0.30045086]] , b =  [-13.10438044]\n",
      "step =  10000 error value =  0.40512057700564946 W =  [[1.27942997]\n",
      " [0.3118517 ]] , b =  [-13.31007571]\n",
      "step =  10400 error value =  0.39503709618610333 W =  [[1.29419357]\n",
      " [0.32306111]] , b =  [-13.51035406]\n",
      "step =  10800 error value =  0.38545955360495054 W =  [[1.30852769]\n",
      " [0.33407354]] , b =  [-13.70553695]\n",
      "step =  11200 error value =  0.37634740626885427 W =  [[1.3224658 ]\n",
      " [0.34488551]] , b =  [-13.89591271]\n",
      "step =  11600 error value =  0.36766483103443703 W =  [[1.33603721]\n",
      " [0.35549526]] , b =  [-14.08174143]\n",
      "step =  12000 error value =  0.3593799936036529 W =  [[1.34926765]\n",
      " [0.3659026 ]] , b =  [-14.2632589]\n",
      "step =  12400 error value =  0.35146445560086426 W =  [[1.36217979]\n",
      " [0.37610854]] , b =  [-14.44067994]\n",
      "step =  12800 error value =  0.3438926899491273 W =  [[1.37479366]\n",
      " [0.38611515]] , b =  [-14.61420112]\n",
      "step =  13200 error value =  0.33664168180941456 W =  [[1.38712706]\n",
      " [0.39592531]] , b =  [-14.78400306]\n",
      "step =  13600 error value =  0.32969059760084374 W =  [[1.39919584]\n",
      " [0.40554253]] , b =  [-14.95025233]\n",
      "step =  14000 error value =  0.3230205085696124 W =  [[1.41101422]\n",
      " [0.4149708 ]] , b =  [-15.11310305]\n",
      "step =  14400 error value =  0.31661415836257173 W =  [[1.42259499]\n",
      " [0.42421447]] , b =  [-15.27269835]\n",
      "step =  14800 error value =  0.31045576633808303 W =  [[1.43394971]\n",
      " [0.43327812]] , b =  [-15.42917142]\n",
      "step =  15200 error value =  0.30453086009138236 W =  [[1.44508887]\n",
      " [0.4421665 ]] , b =  [-15.58264663]\n",
      "step =  15600 error value =  0.298826132016226 W =  [[1.45602206]\n",
      " [0.45088442]] , b =  [-15.73324035]\n",
      "step =  16000 error value =  0.29332931576694193 W =  [[1.46675807]\n",
      " [0.45943675]] , b =  [-15.8810617]\n",
      "step =  16400 error value =  0.2880290792977106 W =  [[1.47730495]\n",
      " [0.46782832]] , b =  [-16.02621323]\n",
      "step =  16800 error value =  0.2829149317924748 W =  [[1.48767018]\n",
      " [0.4760639 ]] , b =  [-16.16879149]\n",
      "step =  17200 error value =  0.2779771423013296 W =  [[1.49786066]\n",
      " [0.4841482 ]] , b =  [-16.30888756]\n",
      "step =  17600 error value =  0.2732066682967471 W =  [[1.50788284]\n",
      " [0.49208582]] , b =  [-16.44658744]\n",
      "step =  18000 error value =  0.26859509268020515 W =  [[1.5177427 ]\n",
      " [0.49988125]] , b =  [-16.58197254]\n",
      "step =  18400 error value =  0.2641345680238142 W =  [[1.52744587]\n",
      " [0.50753884]] , b =  [-16.71511995]\n",
      "step =  18800 error value =  0.25981776703608755 W =  [[1.53699762]\n",
      " [0.51506283]] , b =  [-16.84610283]\n",
      "step =  19200 error value =  0.25563783840690646 W =  [[1.5464029 ]\n",
      " [0.52245731]] , b =  [-16.97499066]\n",
      "step =  19600 error value =  0.25158836732151707 W =  [[1.5556664 ]\n",
      " [0.52972623]] , b =  [-17.1018495]\n",
      "step =  20000 error value =  0.24766334004394477 W =  [[1.56479253]\n",
      " [0.53687342]] , b =  [-17.22674224]\n",
      "step =  20400 error value =  0.24385711206108246 W =  [[1.57378548]\n",
      " [0.54390255]] , b =  [-17.34972881]\n",
      "step =  20800 error value =  0.2401643793536877 W =  [[1.58264922]\n",
      " [0.55081717]] , b =  [-17.47086636]\n",
      "step =  21200 error value =  0.2365801524231465 W =  [[1.59138752]\n",
      " [0.55762069]] , b =  [-17.59020946]\n",
      "step =  21600 error value =  0.23309973275467782 W =  [[1.60000398]\n",
      " [0.5643164 ]] , b =  [-17.70781024]\n",
      "step =  22000 error value =  0.22971869144151538 W =  [[1.60850201]\n",
      " [0.57090746]] , b =  [-17.82371856]\n",
      "step =  22400 error value =  0.22643284973150754 W =  [[1.61688488]\n",
      " [0.57739691]] , b =  [-17.93798213]\n",
      "step =  22800 error value =  0.22323826128829652 W =  [[1.62515572]\n",
      " [0.58378767]] , b =  [-18.05064664]\n",
      "step =  23200 error value =  0.22013119598610803 W =  [[1.63331751]\n",
      " [0.59008256]] , b =  [-18.16175588]\n",
      "step =  23600 error value =  0.21710812507943344 W =  [[1.64137312]\n",
      " [0.59628427]] , b =  [-18.27135186]\n",
      "step =  24000 error value =  0.2141657076084448 W =  [[1.64932527]\n",
      " [0.60239541]] , b =  [-18.37947486]\n",
      "step =  24400 error value =  0.2113007779172204 W =  [[1.65717661]\n",
      " [0.60841849]] , b =  [-18.4861636]\n",
      "step =  24800 error value =  0.2085103341765909 W =  [[1.66492965]\n",
      " [0.61435589]] , b =  [-18.59145526]\n",
      "step =  25200 error value =  0.20579152781549645 W =  [[1.67258684]\n",
      " [0.62020995]] , b =  [-18.69538559]\n",
      "step =  25600 error value =  0.20314165377543927 W =  [[1.68015049]\n",
      " [0.62598289]] , b =  [-18.79798898]\n",
      "step =  26000 error value =  0.20055814151238546 W =  [[1.68762287]\n",
      " [0.63167685]] , b =  [-18.89929852]\n",
      "step =  26400 error value =  0.19803854667812248 W =  [[1.69500613]\n",
      " [0.6372939 ]] , b =  [-18.99934609]\n",
      "step =  26800 error value =  0.19558054342066042 W =  [[1.70230236]\n",
      " [0.64283604]] , b =  [-19.09816239]\n",
      "step =  27200 error value =  0.193181917249221 W =  [[1.70951357]\n",
      " [0.64830516]] , b =  [-19.19577701]\n",
      "step =  27600 error value =  0.19084055841515327 W =  [[1.71664171]\n",
      " [0.65370313]] , b =  [-19.2922185]\n",
      "step =  28000 error value =  0.18855445576495075 W =  [[1.72368865]\n",
      " [0.65903172]] , b =  [-19.3875144]\n",
      "step =  28400 error value =  0.18632169102569723 W =  [[1.7306562 ]\n",
      " [0.66429265]] , b =  [-19.48169127]\n",
      "step =  28800 error value =  0.18414043348732695 W =  [[1.7375461 ]\n",
      " [0.66948758]] , b =  [-19.5747748]\n",
      "step =  29200 error value =  0.18200893504936785 W =  [[1.74436006]\n",
      " [0.6746181 ]] , b =  [-19.66678977]\n",
      "step =  29600 error value =  0.17992552560286346 W =  [[1.7510997 ]\n",
      " [0.67968575]] , b =  [-19.75776014]\n",
      "step =  30000 error value =  0.17788860872109594 W =  [[1.75776662]\n",
      " [0.68469204]] , b =  [-19.84770908]\n",
      "step =  30400 error value =  0.17589665763472243 W =  [[1.76436234]\n",
      " [0.68963838]] , b =  [-19.93665899]\n",
      "step =  30800 error value =  0.17394821146964567 W =  [[1.77088834]\n",
      " [0.69452618]] , b =  [-20.02463156]\n",
      "step =  31200 error value =  0.17204187172738228 W =  [[1.77734607]\n",
      " [0.69935677]] , b =  [-20.11164776]\n",
      "step =  31600 error value =  0.1701762989898623 W =  [[1.78373693]\n",
      " [0.70413146]] , b =  [-20.19772792]\n",
      "step =  32000 error value =  0.16835020983181162 W =  [[1.79006225]\n",
      " [0.7088515 ]] , b =  [-20.28289171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  32400 error value =  0.16656237392568482 W =  [[1.79632336]\n",
      " [0.7135181 ]] , b =  [-20.3671582]\n",
      "step =  32800 error value =  0.16481161132494748 W =  [[1.80252153]\n",
      " [0.71813245]] , b =  [-20.45054588]\n",
      "step =  33200 error value =  0.16309678991303642 W =  [[1.80865798]\n",
      " [0.72269567]] , b =  [-20.53307266]\n",
      "step =  33600 error value =  0.16141682300627716 W =  [[1.81473393]\n",
      " [0.72720887]] , b =  [-20.61475591]\n",
      "step =  34000 error value =  0.15977066709982765 W =  [[1.82075053]\n",
      " [0.73167313]] , b =  [-20.69561251]\n",
      "step =  34400 error value =  0.15815731974687477 W =  [[1.82670892]\n",
      " [0.73608946]] , b =  [-20.77565881]\n",
      "step =  34800 error value =  0.15657581756175648 W =  [[1.83261019]\n",
      " [0.74045887]] , b =  [-20.85491069]\n",
      "step =  35200 error value =  0.15502523433879895 W =  [[1.83845542]\n",
      " [0.74478234]] , b =  [-20.93338358]\n",
      "step =  35600 error value =  0.15350467927892614 W =  [[1.84424563]\n",
      " [0.74906081]] , b =  [-21.01109247]\n",
      "step =  36000 error value =  0.15201329531688212 W =  [[1.84998185]\n",
      " [0.75329518]] , b =  [-21.0880519]\n",
      "step =  36400 error value =  0.15055025754260765 W =  [[1.85566506]\n",
      " [0.75748636]] , b =  [-21.16427603]\n",
      "step =  36800 error value =  0.1491147717103898 W =  [[1.86129621]\n",
      " [0.76163519]] , b =  [-21.2397786]\n",
      "step =  37200 error value =  0.14770607283027884 W =  [[1.86687623]\n",
      " [0.76574251]] , b =  [-21.31457298]\n",
      "step =  37600 error value =  0.14632342383644925 W =  [[1.87240603]\n",
      " [0.76980913]] , b =  [-21.38867219]\n",
      "step =  38000 error value =  0.1449661143276717 W =  [[1.8778865 ]\n",
      " [0.77383585]] , b =  [-21.46208887]\n",
      "step =  38400 error value =  0.14363345937529443 W =  [[1.88331848]\n",
      " [0.77782343]] , b =  [-21.53483534]\n",
      "step =  38800 error value =  0.1423247983946553 W =  [[1.88870283]\n",
      " [0.7817726 ]] , b =  [-21.60692358]\n",
      "step =  39200 error value =  0.14103949407586833 W =  [[1.89404035]\n",
      " [0.7856841 ]] , b =  [-21.67836526]\n",
      "step =  39600 error value =  0.13977693137053288 W =  [[1.89933185]\n",
      " [0.78955863]] , b =  [-21.74917175]\n",
      "step =  40000 error value =  0.13853651653077836 W =  [[1.90457809]\n",
      " [0.79339686]] , b =  [-21.8193541]\n",
      "step =  40400 error value =  0.13731767619773902 W =  [[1.90977983]\n",
      " [0.79719948]] , b =  [-21.8889231]\n",
      "step =  40800 error value =  0.1361198565362982 W =  [[1.91493782]\n",
      " [0.80096711]] , b =  [-21.95788925]\n",
      "step =  41200 error value =  0.1349425224135404 W =  [[1.92005277]\n",
      " [0.8047004 ]] , b =  [-22.02626281]\n",
      "step =  41600 error value =  0.13378515661828716 W =  [[1.92512539]\n",
      " [0.80839996]] , b =  [-22.09405374]\n",
      "step =  42000 error value =  0.1326472591193079 W =  [[1.93015635]\n",
      " [0.81206638]] , b =  [-22.1612718]\n",
      "step =  42400 error value =  0.1315283463600864 W =  [[1.93514633]\n",
      " [0.81570024]] , b =  [-22.22792646]\n",
      "step =  42800 error value =  0.13042795058794068 W =  [[1.94009598]\n",
      " [0.81930212]] , b =  [-22.294027]\n",
      "step =  43200 error value =  0.1293456192156392 W =  [[1.94500594]\n",
      " [0.82287256]] , b =  [-22.35958245]\n",
      "step =  43600 error value =  0.12828091421368112 W =  [[1.94987683]\n",
      " [0.8264121 ]] , b =  [-22.42460163]\n",
      "step =  44000 error value =  0.12723341153148027 W =  [[1.95470927]\n",
      " [0.82992126]] , b =  [-22.48909314]\n",
      "step =  44400 error value =  0.12620270054592436 W =  [[1.95950384]\n",
      " [0.83340057]] , b =  [-22.5530654]\n",
      "step =  44800 error value =  0.12518838353582076 W =  [[1.96426112]\n",
      " [0.83685051]] , b =  [-22.61652661]\n",
      "step =  45200 error value =  0.12419007518072091 W =  [[1.96898169]\n",
      " [0.84027157]] , b =  [-22.67948478]\n",
      "step =  45600 error value =  0.1232074020829562 W =  [[1.97366609]\n",
      " [0.84366422]] , b =  [-22.74194774]\n",
      "step =  46000 error value =  0.12224000231152424 W =  [[1.97831488]\n",
      " [0.84702894]] , b =  [-22.80392314]\n",
      "step =  46400 error value =  0.12128752496672118 W =  [[1.98292857]\n",
      " [0.85036616]] , b =  [-22.86541845]\n",
      "step =  46800 error value =  0.1203496297644408 W =  [[1.9875077 ]\n",
      " [0.85367634]] , b =  [-22.92644097]\n",
      "step =  47200 error value =  0.11942598663908006 W =  [[1.99205277]\n",
      " [0.8569599 ]] , b =  [-22.98699786]\n",
      "step =  47600 error value =  0.11851627536408962 W =  [[1.99656427]\n",
      " [0.86021726]] , b =  [-23.04709608]\n",
      "step =  48000 error value =  0.11762018518931293 W =  [[2.00104269]\n",
      " [0.86344883]] , b =  [-23.10674246]\n",
      "step =  48400 error value =  0.11673741449415868 W =  [[2.00548851]\n",
      " [0.86665502]] , b =  [-23.16594368]\n",
      "step =  48800 error value =  0.11586767045590839 W =  [[2.00990219]\n",
      " [0.86983621]] , b =  [-23.22470626]\n",
      "step =  49200 error value =  0.1150106687323387 W =  [[2.01428419]\n",
      " [0.87299279]] , b =  [-23.2830366]\n",
      "step =  49600 error value =  0.11416613315791319 W =  [[2.01863495]\n",
      " [0.87612513]] , b =  [-23.34094094]\n",
      "step =  50000 error value =  0.11333379545301446 W =  [[2.02295491]\n",
      " [0.8792336 ]] , b =  [-23.3984254]\n",
      "step =  50400 error value =  0.11251339494533918 W =  [[2.0272445 ]\n",
      " [0.88231856]] , b =  [-23.45549597]\n",
      "step =  50800 error value =  0.11170467830309833 W =  [[2.03150413]\n",
      " [0.88538035]] , b =  [-23.5121585]\n",
      "step =  51200 error value =  0.1109073992792774 W =  [[2.03573423]\n",
      " [0.88841932]] , b =  [-23.56841874]\n",
      "step =  51600 error value =  0.11012131846653453 W =  [[2.03993518]\n",
      " [0.89143581]] , b =  [-23.62428229]\n",
      "step =  52000 error value =  0.10934620306214972 W =  [[2.04410739]\n",
      " [0.89443013]] , b =  [-23.67975467]\n",
      "step =  52400 error value =  0.10858182664260294 W =  [[2.04825123]\n",
      " [0.89740261]] , b =  [-23.73484126]\n",
      "step =  52800 error value =  0.10782796894728543 W =  [[2.0523671 ]\n",
      " [0.90035356]] , b =  [-23.78954734]\n",
      "step =  53200 error value =  0.1070844156709268 W =  [[2.05645535]\n",
      " [0.9032833 ]] , b =  [-23.84387808]\n",
      "step =  53600 error value =  0.10635095826434084 W =  [[2.06051636]\n",
      " [0.90619211]] , b =  [-23.89783855]\n",
      "step =  54000 error value =  0.10562739374310648 W =  [[2.06455048]\n",
      " [0.9090803 ]] , b =  [-23.95143371]\n",
      "step =  54400 error value =  0.10491352450381265 W =  [[2.06855806]\n",
      " [0.91194815]] , b =  [-24.00466843]\n",
      "step =  54800 error value =  0.10420915814751949 W =  [[2.07253944]\n",
      " [0.91479594]] , b =  [-24.05754749]\n",
      "step =  55200 error value =  0.10351410731007396 W =  [[2.07649496]\n",
      " [0.91762395]] , b =  [-24.11007556]\n",
      "step =  55600 error value =  0.10282818949904322 W =  [[2.08042495]\n",
      " [0.92043246]] , b =  [-24.16225723]\n",
      "step =  56000 error value =  0.10215122693693118 W =  [[2.08432974]\n",
      " [0.92322171]] , b =  [-24.214097]\n",
      "step =  56400 error value =  0.10148304641038615 W =  [[2.08820964]\n",
      " [0.92599199]] , b =  [-24.26559928]\n",
      "step =  56800 error value =  0.10082347912512186 W =  [[2.09206495]\n",
      " [0.92874353]] , b =  [-24.31676839]\n",
      "step =  57200 error value =  0.10017236056636818 W =  [[2.095896  ]\n",
      " [0.93147659]] , b =  [-24.36760858]\n",
      "step =  57600 error value =  0.09952953036451406 W =  [[2.09970308]\n",
      " [0.93419141]] , b =  [-24.41812402]\n",
      "step =  58000 error value =  0.09889483216583331 W =  [[2.10348649]\n",
      " [0.93688824]] , b =  [-24.46831879]\n",
      "step =  58400 error value =  0.0982681135079312 W =  [[2.10724651]\n",
      " [0.9395673 ]] , b =  [-24.5181969]\n",
      "step =  58800 error value =  0.09764922569986835 W =  [[2.11098342]\n",
      " [0.94222883]] , b =  [-24.56776229]\n",
      "step =  59200 error value =  0.0970380237065768 W =  [[2.11469752]\n",
      " [0.94487306]] , b =  [-24.61701882]\n",
      "step =  59600 error value =  0.09643436603759278 W =  [[2.11838907]\n",
      " [0.9475002 ]] , b =  [-24.66597029]\n",
      "step =  60000 error value =  0.09583811463976459 W =  [[2.12205834]\n",
      " [0.95011047]] , b =  [-24.71462042]\n",
      "step =  60400 error value =  0.09524913479383099 W =  [[2.1257056]\n",
      " [0.9527041]] , b =  [-24.76297287]\n",
      "step =  60800 error value =  0.09466729501470006 W =  [[2.1293311 ]\n",
      " [0.95528128]] , b =  [-24.81103122]\n",
      "step =  61200 error value =  0.09409246695529762 W =  [[2.13293511]\n",
      " [0.95784222]] , b =  [-24.858799]\n",
      "step =  61600 error value =  0.09352452531379955 W =  [[2.13651787]\n",
      " [0.96038712]] , b =  [-24.90627968]\n",
      "step =  62000 error value =  0.09296334774411519 W =  [[2.14007962]\n",
      " [0.96291619]] , b =  [-24.95347666]\n",
      "step =  62400 error value =  0.09240881476954094 W =  [[2.14362062]\n",
      " [0.96542961]] , b =  [-25.00039328]\n",
      "step =  62800 error value =  0.09186080969936962 W =  [[2.14714111]\n",
      " [0.96792758]] , b =  [-25.04703283]\n",
      "step =  63200 error value =  0.09131921854843582 W =  [[2.1506413 ]\n",
      " [0.97041028]] , b =  [-25.09339853]\n",
      "step =  63600 error value =  0.09078392995938599 W =  [[2.15412144]\n",
      " [0.9728779 ]] , b =  [-25.13949355]\n",
      "step =  64000 error value =  0.09025483512759132 W =  [[2.15758175]\n",
      " [0.97533062]] , b =  [-25.18532102]\n",
      "step =  64400 error value =  0.08973182772869968 W =  [[2.16102246]\n",
      " [0.97776861]] , b =  [-25.23088399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  64800 error value =  0.08921480384853461 W =  [[2.16444378]\n",
      " [0.98019206]] , b =  [-25.27618548]\n",
      "step =  65200 error value =  0.08870366191541235 W =  [[2.16784592]\n",
      " [0.98260112]] , b =  [-25.32122845]\n",
      "step =  65600 error value =  0.08819830263469666 W =  [[2.17122911]\n",
      " [0.98499598]] , b =  [-25.36601581]\n",
      "step =  66000 error value =  0.08769862892555093 W =  [[2.17459354]\n",
      " [0.98737679]] , b =  [-25.41055042]\n",
      "step =  66400 error value =  0.0872045458597531 W =  [[2.17793943]\n",
      " [0.98974373]] , b =  [-25.45483509]\n",
      "step =  66800 error value =  0.08671596060255982 W =  [[2.18126697]\n",
      " [0.99209693]] , b =  [-25.4988726]\n",
      "step =  67200 error value =  0.0862327823554727 W =  [[2.18457636]\n",
      " [0.99443658]] , b =  [-25.54266567]\n",
      "step =  67600 error value =  0.08575492230089303 W =  [[2.1878678 ]\n",
      " [0.99676281]] , b =  [-25.58621697]\n",
      "step =  68000 error value =  0.08528229354853274 W =  [[2.19114148]\n",
      " [0.99907578]] , b =  [-25.62952915]\n",
      "step =  68400 error value =  0.08481481108359429 W =  [[2.19439759]\n",
      " [1.00137564]] , b =  [-25.67260479]\n",
      "step =  68800 error value =  0.0843523917165864 W =  [[2.19763632]\n",
      " [1.00366254]] , b =  [-25.71544644]\n",
      "step =  69200 error value =  0.08389495403473193 W =  [[2.20085784]\n",
      " [1.00593662]] , b =  [-25.75805662]\n",
      "step =  69600 error value =  0.08344241835492779 W =  [[2.20406234]\n",
      " [1.00819803]] , b =  [-25.80043779]\n",
      "step =  70000 error value =  0.08299470667820653 W =  [[2.20725   ]\n",
      " [1.01044689]] , b =  [-25.84259238]\n",
      "step =  70400 error value =  0.08255174264558225 W =  [[2.21042099]\n",
      " [1.01268336]] , b =  [-25.88452279]\n",
      "step =  70800 error value =  0.0821134514952963 W =  [[2.21357548]\n",
      " [1.01490755]] , b =  [-25.92623137]\n",
      "step =  71200 error value =  0.08167976002141655 W =  [[2.21671364]\n",
      " [1.01711962]] , b =  [-25.96772044]\n",
      "step =  71600 error value =  0.0812505965336675 W =  [[2.21983564]\n",
      " [1.01931968]] , b =  [-26.00899228]\n",
      "step =  72000 error value =  0.08082589081853157 W =  [[2.22294165]\n",
      " [1.02150787]] , b =  [-26.05004914]\n",
      "step =  72400 error value =  0.08040557410153096 W =  [[2.22603182]\n",
      " [1.02368432]] , b =  [-26.09089323]\n",
      "step =  72800 error value =  0.07998957901062942 W =  [[2.22910631]\n",
      " [1.02584914]] , b =  [-26.13152673]\n",
      "step =  73200 error value =  0.07957783954080003 W =  [[2.23216528]\n",
      " [1.02800246]] , b =  [-26.17195178]\n",
      "step =  73600 error value =  0.07917029101960837 W =  [[2.23520889]\n",
      " [1.0301444 ]] , b =  [-26.2121705]\n",
      "step =  74000 error value =  0.07876687007382707 W =  [[2.23823729]\n",
      " [1.03227509]] , b =  [-26.25218497]\n",
      "step =  74400 error value =  0.0783675145971052 W =  [[2.24125062]\n",
      " [1.03439463]] , b =  [-26.29199724]\n",
      "step =  74800 error value =  0.07797216371852506 W =  [[2.24424905]\n",
      " [1.03650314]] , b =  [-26.33160932]\n",
      "step =  75200 error value =  0.07758075777213574 W =  [[2.2472327 ]\n",
      " [1.03860073]] , b =  [-26.37102321]\n",
      "step =  75600 error value =  0.07719323826735763 W =  [[2.25020173]\n",
      " [1.04068753]] , b =  [-26.41024087]\n",
      "step =  76000 error value =  0.07680954786025367 W =  [[2.25315628]\n",
      " [1.04276363]] , b =  [-26.44926423]\n",
      "step =  76400 error value =  0.07642963032567425 W =  [[2.25609648]\n",
      " [1.04482914]] , b =  [-26.48809519]\n",
      "step =  76800 error value =  0.07605343053014584 W =  [[2.25902248]\n",
      " [1.04688418]] , b =  [-26.52673563]\n",
      "step =  77200 error value =  0.07568089440559077 W =  [[2.2619344 ]\n",
      " [1.04892884]] , b =  [-26.56518739]\n",
      "step =  77600 error value =  0.07531196892378646 W =  [[2.26483239]\n",
      " [1.05096324]] , b =  [-26.6034523]\n",
      "step =  78000 error value =  0.07494660207155399 W =  [[2.26771658]\n",
      " [1.05298746]] , b =  [-26.64153215]\n",
      "step =  78400 error value =  0.07458474282664616 W =  [[2.27058709]\n",
      " [1.05500162]] , b =  [-26.67942871]\n",
      "step =  78800 error value =  0.07422634113433349 W =  [[2.27344406]\n",
      " [1.05700581]] , b =  [-26.71714373]\n",
      "step =  79200 error value =  0.07387134788461824 W =  [[2.2762876 ]\n",
      " [1.05900013]] , b =  [-26.75467893]\n",
      "step =  79600 error value =  0.07351971489013616 W =  [[2.27911785]\n",
      " [1.06098468]] , b =  [-26.792036]\n",
      "step =  80000 error value =  0.07317139486462823 W =  [[2.28193493]\n",
      " [1.06295954]] , b =  [-26.82921662]\n"
     ]
    }
   ],
   "source": [
    "# multi-variable logistic regression(classification) - example\n",
    "\n",
    "# 1) 학습데이터(Training Data) 준비\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([ [2,4], [4,11], [6,6], [8,5], [10,7], [12,16], [14,8], [16,3], [18,7] ])\n",
    "t_data = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1]).reshape(9,1)\n",
    "\n",
    "# 2) 임의의 직선 z = W1x1 + W2x2 + b 정의 (가중치 W, 바이어스 b 초기화)\n",
    "\n",
    "W = np.random.rand(2,1) # 2X1 행렬\n",
    "b = np.random.rand(1)\n",
    "print(\"W = \", W, \", W.shape = \", W.shape, \", b = \", b, \", b.shape = \", b.shape)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def loss_func(x, t):\n",
    "    delta = 1e-7 # log 무한대 발산 방지\n",
    "    \n",
    "    z = np.dot(x, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    # cross-entropy\n",
    "    return -np.sum( t*np.log(y + delta) + (1-t) * np.log((1-y) + delta ))\n",
    "\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags = ['multi_index'], op_flags = ['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x\n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad\n",
    "\n",
    "def error_val(x, t):\n",
    "    delta = 1e-7 # log 무한대 발산 방지\n",
    "    \n",
    "    z = np.dot(x, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    # cross-entropy\n",
    "    return -np.sum( t*np.log(y + delta) + (1-t)*np.log((1-y) + delta))\n",
    "\n",
    "def predict(x):\n",
    "    z = np.dot(x,W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    if y > 0.5:\n",
    "        result = 1 # True\n",
    "    else:\n",
    "        result = 0 # False\n",
    "        \n",
    "    return y, result\n",
    "\n",
    "# 5) 학습율 초기화 및 손실함수가 최소가 될 때까지 W, b 업데이트\n",
    "\n",
    "learning_rate  = 1e-2\n",
    "\n",
    "f = lambda x : loss_func(x_data, t_data)\n",
    "\n",
    "print(\"initial error value = \", error_val(x_data, t_data), \"initial W = \", W, \"\\n\", \", b = \", b)\n",
    "\n",
    "for step in range(80001):\n",
    "    W -= learning_rate * numerical_derivative(f, W)\n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "    \n",
    "    if (step % 400 == 0):\n",
    "        print(\"step = \", step, \"error value = \", error_val(x_data, t_data), \"W = \", W, \", b = \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f42358b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.12863303]), 0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([3, 17]) # (예습, 복습) = (3, 17) => Fail (0)\n",
    "predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eda1da2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.00099094]), 0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([5, 8])\n",
    "predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b212492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.99998952]), 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([7, 21])\n",
    "predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "079ade00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.63506371]), 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([12, 0])\n",
    "predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e5668f",
   "metadata": {},
   "source": [
    "미래값을 예측해보면, 복습보다는 예습시간이 합격(Pass)에 미치는 영향이 크다는 것을 알 수 있음\n",
    "\n",
    "즉, 예습시간에 대한 가중치 W1 = 2.28, 복습시간에 대한 가중치 W2 = 1.06 에서 보듯이 예습시간이 복습시간에 비해 최종결과에 미치는 영향이 2배 이상임."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
